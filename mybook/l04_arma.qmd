---

editor_options:
    chunk_output_type: console
---

```{r, echo=FALSE}
library(dplyr)
library(ggplot2)
library(patchwork)
options(digits = 3)
theme_set(theme_light())
```

# 자기회귀 이동평균 (ARMA) 모형

이 강의의 목표는 정상 시계열에 대한 광범위한 모형 종류인 자기회귀 이동평균(ARMA) 모형을 소개하는 것입니다.
AR과 MA 구성 요소의 차이점을 인식하고 실제로 이러한 모형을 구현하는 방법을 배워야 합니다.

**학습 목표**

1. 정상 시계열에 대한 AR($p$), MA($q$) 및 ARMA($p,q$) 모형을 정의합니다.
1. ACF 및 PACF 그림을 사용하여 차수 $p$와 $q$를 식별합니다.
1. 다양한 방법을 사용하여 모형을 추정하고 정보 기준(AIC 또는 BIC)을 사용하여 모형을 선택합니다.
1. ARMA 모형의 잔차를 진단합니다.
1. ARMA 모형에서 예측값을 얻습니다.

**읽기 자료**

* @Brockwell:Davis:2002의 2, 3, 5장


## 소개

시계열에서 추세와 강한 계절성을 제거하거나 모델링한 후, 자기 상관이 있거나 조건부 이분산성을 가질 수 있는 정상 나머지를 처리해야 합니다.
여기서는 시계열의 자기 상관을 다루는 광범위한 ARMA 모형 종류를 소개합니다.

시계열은 평균과 자기 공분산이 시간 $t$에 의존하지 않고 자기 공분산이 시차 $h$에만 의존하는 경우 (약하게) 정상이라고 합니다.
AR, MA 또는 ARMA로 모델링할 시계열 프로세스가 정상임을 보이기 위해 이 두 가지 조건을 사용할 것입니다.
자기 상관의 존재가 추세가 있음을 의미하지는 않는다는 것을 기억하십시오.

백색 잡음 및 랜덤 워크와 같은 다른 일반적인 단변량 프로세스에 대한 두 가지 조건을 확인하는 것으로 시작합니다.

```{r}
# 재현 가능한 난수 생성을 위한 시드 설정
set.seed(123) 
T <- 300L
Lag <- 0:15
```

이 강의의 대부분 예제는 특정 유형의 프로세스에서 시뮬레이션된 시계열을 샘플링하더라도 표본 자기 상관이 이론적 자기 상관과 어떻게 다를 수 있는지 보여주기 위해 시뮬레이션되었습니다.
모든 시뮬레이션된 계열의 길이는 `r T`입니다.

::: {.callout-note icon=false}
        
## 예시: 백색 잡음의 정상성 확인

$X_t$를 백색 잡음 계열, $X_t \sim \mathrm{WN}(0, \sigma^2)$이라고 합시다.
$X_t$가 약하게 정상임을 보이십시오.

모든 $t$에 대해 $\mathrm{E}(X_t) = 0$ $\Rightarrow$ $\mathrm{E}(X_t)$는 $t$에 독립적입니다.

이제 자기 공분산을 확인합니다.
$$
\begin{align}
\mathrm{cov}(X_t, X_{t+h}) &=
\begin{cases}
\mathrm{cov}(X_t, X_t) & \text{if } h = 0\\
0                      & \text{otherwise}
\end{cases} \\
& =
\begin{cases}
\mathrm{var}(X_t) & \text{if } h = 0\\
0                 & \text{otherwise}
\end{cases} \\
& =
\begin{cases}
\sigma^2 & \text{if } h = 0\\
0        & \text{otherwise}
\end{cases}
\end{align}
$$

$\Rightarrow$ $\mathrm{cov}(X_t, X_{t+h})$는 $t$에 의존하지 않고 $h$에만 의존합니다.

약한 정상성의 두 조건이 모두 충족되므로 $X_t$는 약하게 정상입니다.
:::

@eq-wn에 지정된 백색 잡음에 대한 그림은 @fig-wn을 참조하십시오.
$$
X_t \sim \text{i.i.d.}\; N(0, \sigma^2);\; \sigma = 2.
$${#eq-wn}

```{r}
#| label: fig-wn
#| fig-cap: "@eq-wn에 지정된 백색 잡음."
#| fig-height: 7

# 이론적 ACF, PACF
RHO <- c(1, rep(0, max(Lag)))

# 표본 데이터
X <- ts(rnorm(T, sd = 2))

# 그림
p1 <- ggplot(data.frame(Lag, ACF = RHO), aes(x = Lag, y = ACF)) +
    geom_bar(stat = "identity") +
    ggtitle("이론적 ACF")
p2 <- ggplot(data.frame(Lag, PACF = RHO), aes(x = Lag, y = PACF)) +
    geom_bar(stat = "identity") +
    ggtitle("이론적 PACF")
p3 <- forecast::autoplot(X) + 
    ggtitle("표본 시계열")
p4 <- forecast::ggAcf(X) + 
    ggtitle("표본 ACF")
p5 <- forecast::ggAcf(X, type = "partial") + 
    ggtitle("표본 PACF")
(plot_spacer() + p1 + p2) / (p3 + p4 + p5) +
    plot_annotation(tag_levels = 'A')
```

::: {.callout-note}
ACF(0) = PACF(0) = 1은 항상 성립한다는 것을 기억하십시오.
일부 R 그림 함수는 0 시차에 대한 결과를 보여주지만(예: `acf()`), 일부는 그렇지 않습니다(예: `pacf()` 및 여기서 사용된 함수 `forecast::ggAcf()`).
:::

::: {.callout-note icon=false}

## 예시: 랜덤 워크의 정상성 확인

랜덤 워크 $S_t$의 정상성을 확인하십시오.
$S_t = \sum_{i=1}^t{X_t}$, 여기서 $X_t \sim \text{i.i.d.}(0,\sigma^2)$이고 $S_0 = 0$입니다.

$\mathrm{E}(S_t) = \mathrm{E}(\sum_{i=1}^t{X_t}) = 0$ $\Rightarrow$ $\mathrm{E}(X_t)$는 $t$에 의존하지 않습니다.

이제 자기 공분산을 확인합니다.
$$
\begin{split}
\mathrm{cov}(S_t, S_{t+h}) &= \mathrm{cov}(S_t, S_t + X_{t+1}+\dots + X_{t+h})\\
& = \mathrm{cov}(S_t, S_t) + \mathrm{cov}(S_t, X_{t+1}+\dots + X_{t+h})\\
& = \mathrm{var}(S_t) + 0\\
& = \mathrm{var}\left(\sum_{i=1}^t{X_t}\right) \\
& = \sum_{i=1}^t\mathrm{var}(X_t)\\
& = t\sigma^2
\end{split}
$$

$S_t$의 자기 공분산은 시간 $t$에 의존하므로 $S_t$는 정상이 아닙니다.
또한 $S_t = S_{t-1} + X_t$이므로 $S_t$는 $\phi_1 = 1$인 비정상 AR(1) 프로세스입니다.
:::

랜덤 워크 패턴은 자연에서 널리 발견되며, 예를 들어 브라운 운동 현상에서 볼 수 있습니다.
비정상 시계열의 ACF에서 느린 선형 감쇠를 주목하십시오(@fig-rw).
$$
S_t = \sum_{i = 1}^t X_i,
$${#eq-rw}
여기서 $X_t \sim \mathrm{i.i.d.}(0, \sigma^2)$이고 $\sigma = 2$입니다.

```{r}
#| label: fig-rw
#| fig-cap: "@eq-rw에 지정된 평균이 0인 랜덤 워크."
#| fig-height: 3

# 표본 데이터
RW0 <- ts(cumsum(X))

# 그림
p3 <- forecast::autoplot(RW0) + 
    ggtitle("표본 시계열")
p4 <- forecast::ggAcf(RW0) + 
    ggtitle("표본 ACF")
p5 <- forecast::ggAcf(RW0, type = "partial") + 
    ggtitle("표본 PACF")
p3 + p4 + p5 +
    plot_annotation(tag_levels = 'A')
```

i.i.d. 프로세스의 평균이 0이 아닌 경우 랜덤 워크는 매우 다르게 보일 수 있습니다.
다음은 드리프트가 있는 랜덤 워크입니다(@fig-rw2).
$$
S_t = \sum_{i = 1}^t X_i,
$${#eq-rw2}
여기서 $X_t \sim \mathrm{i.i.d.}(a, \sigma^2)$, $a = 0.2$이고 $\sigma = 2$입니다.

```{r}
#| label: fig-rw2
#| fig-cap: "@eq-rw2에 지정된 드리프트가 있는 랜덤 워크."
#| fig-height: 3

# 표본 데이터
RW2 <- ts(cumsum(X + 0.2))

# 그림
p3 <- forecast::autoplot(RW2) + 
    ggtitle("표본 시계열")
p4 <- forecast::ggAcf(RW2) + 
    ggtitle("표본 ACF")
p5 <- forecast::ggAcf(RW2, type = "partial") + 
    ggtitle("표본 PACF")
p3 + p4 + p5 +
    plot_annotation(tag_levels = 'A')
```


## 자기회귀 (AR) 모형

**AR(1) 모형**

우리는 이미 AR(1) 모형에 익숙합니다.
$$
Y_{t} = \phi_{1}  Y_{t -1} + \epsilon_{t},
$$
여기서

* $\epsilon_{t}$는 백색 잡음입니다($\mathrm{E}(\epsilon_{t}) = 0$이고 $\mathrm{E}(\epsilon_{t}^2) = \sigma^{2}_{\epsilon}$).
* $\epsilon_{t}$는 $Y_{t - k}, \dots, Y_{t - 1}$과 독립적입니다.
* $\phi_{1}$은 자기회귀 계수입니다.

AR(1) 모형은 다음과 같이 다시 쓸 수 있습니다.
$$
(1 - \phi_{1} B) Y_{t} = \epsilon_{t},
$$
또는 더 간결한 표기법으로
$$
\phi(B)Y_t = \epsilon_t,
$$
여기서 $\phi(\lambda)$는 다항식 $\phi (\lambda) = 1 - \phi_{1} \lambda$입니다.

$Y_{t}$의 분산을 구해 봅시다.
$$
\begin{split}
\mathrm{var} (Y_{t} ) = \mathrm{E} ( \phi_{1} Y_{t - 1} + \epsilon_{t})^{2} & =  \mathrm{E} ( \phi^{2}_{1} Y^{2}_{t - 1} + 2 \phi_{1} Y_{t-1}  \epsilon_{t} + \epsilon^{2}_{ t}) \\
\\
& = \phi^{2}_{1} \mathrm{E}(Y^{2}_{t - 1}) + 2\phi_{1} \mathrm{E} (Y_{t - 1} \epsilon_{t}) + \mathrm{E}(\epsilon^{2}_{t}) \\
\\
& = \phi^{2}_{1} \mathrm{var} \left( Y_{t -1} \right) + 0 + \sigma^{2}_{\epsilon} \\
\\
& = \phi^{2}_{1} \mathrm{var} \left( Y_{t -1} \right) + \sigma^{2}_{\epsilon}.
\end{split}
$$

따라서 $\phi_{1} \neq \pm 1$이면 다음과 같습니다.
$$
\sigma^{2}_{Y} = \frac{\sigma^{2}_{\epsilon}} {1 - \phi^{2}_{1}}.
$${#eq-ar1var}

::: {.callout-note}
@eq-ar1var가 의미를 가지려면 $|\phi_{1}| < 1$이 필요합니다.
이것은 AR(1) 프로세스가 (*약하게*) *정상*인 조건입니다.
예를 들어, $\phi_{1} = \pm 1$이면 프로세스는 랜덤 워크이며 정상이 아닙니다.
나중에 모든 AR 프로세스에는 이러한 성격의 조건이 필요하다는 것을 알게 될 것입니다.
:::

::: {.callout-note icon=false}
        
## 예시: AR(1)의 정상성 확인

$Y_t = \phi Y_{t-1} + \epsilon_t$, $|\phi| < 1$이고 $\epsilon_t \sim \mathrm{WN}(0, \sigma^2)$일 때 AR(1) 프로세스 $Y_t$가 정상임을 확인하십시오.

$$
\begin{split}
\mathrm{E}(Y_t) &= \mathrm{E}(\phi Y_{t-1} + \epsilon_t)\\
& = \phi \mathrm{E}(Y_{t-1}) + \mathrm{E}(\epsilon_t)\\
& = \phi^2 \mathrm{E}(Y_{t-2}) + 0\\
& = \phi^3 \mathrm{E}(Y_{t-3})\\
& = \dots\\
& = \phi^N \mathrm{E}(Y_{t-N})\\
\lim_{N \rightarrow \infty} \mathrm{E}(Y_t) &= \lim_{N \rightarrow \infty} \phi^N \mathrm{E}(Y_{t-N}) = 0
\end{split}
$$
따라서 $Y_t$의 평균은 시간에 의존하지 않습니다.

이제 자기 공분산을 확인합니다.
$h=0$일 때 $\mathrm{cov}(Y_t, Y_{t}) = \mathrm{var}(Y_t) = \sigma^2_Y$이며, 이는 @eq-ar1var에서 유도되었고 시간에 의존하지 않습니다.

$h \neq 0$일 때,
$$
\begin{split}
\mathrm{cov}(Y_t, Y_{t-h}) &= \mathrm{cov}(\phi Y_{t-1} + \epsilon_t, Y_{t-h})\\
& = \mathrm{cov}(\phi Y_{t-1}, Y_{t-h}) + \mathrm{cov}(\epsilon_t, Y_{t-h})\\
& = \phi \mathrm{cov}(Y_{t-1}, Y_{t-h}) + 0\\
& = \phi \mathrm{cov}(\phi Y_{t-2} + \epsilon_{t-1}, Y_{t-h})\\
& = \phi^2 \gamma_Y(h-2)\\
& = \dots\\
& = \phi^h \gamma_Y(0) \\
& = \phi^h \sigma_Y^2,
\end{split}
$$
따라서 자기 공분산은 시간에 의존하지 않고 시차 $h$에만 의존합니다.

약한 정상성의 두 조건이 모두 충족되므로 위에 지정된 $Y_t$는 약하게 정상입니다.
:::

::: {.callout-note}
또한 AR(1) 프로세스의 ACF
$$
\rho_Y(h) = \frac{\gamma_Y(h)}{\gamma_Y(0)} = \frac{\phi^h \gamma_Y(0)}{\gamma_Y(0)} = \phi^h
$${#eq-arACF}
는 지수적 감쇠를 보여줍니다. AR 프로세스에 대해 이것을 기억하십시오.
:::

**AR($p$) 모형**

이제 AR(1) 모형을 다음과 같이 확장할 수 있습니다.
$$ 
\begin{split}
Y_{t} &= \phi_{1} Y_{t  - 1} + \phi_{2} Y_{t - 2} + \dots + \phi_{p} Y_{t - p} + \epsilon_{t} \\
&=\sum_{i=1}^p\phi_iY_{t-i} + \epsilon_t
\end{split}
$${#eq-ARp}
여기서 $\epsilon_{t}$는 $Y_{t - k}, \dots , Y_{t - 1}$과 독립적이고 $p \in \mathbb{N}^{+}$입니다.
이 모형을 *차수 $p$의 자기회귀 모형* 또는 간단히 *AR($p$) 모형*이라고 합니다.

AR(1)과 유사하게 모든 AR($p$) 모형은 다음과 같이 다시 쓸 수 있습니다.
$$
\left(1 -  \sum^{p}_{i = 1} \phi_{i} B^{i} \right) Y_{t} = \epsilon_{t},
$$
또는 더 간결한 표기법으로
$$
\phi (B) Y_t = \epsilon_t,
$$
여기서 $\phi(\lambda)$는 다항식 $\phi(\lambda) = 1 - \phi_{1} \lambda - \phi_{2} \lambda^{2} - \dots - \phi_{p} \lambda^{p}$입니다.

AR($p$) 모형의 정상성 조건은 다항식 $\phi(\lambda)$를 통해 정의됩니다.
구체적으로, *함수 $\phi(\lambda)$의 모든 근은 복소 평면의 단위 원 외부에 있습니다*.

**AR 프로세스의 ACF**

AR($p$) 모형에 대한 ACVF 및 ACF를 계산하기 위해 @eq-ARp의 양변에 $k \geqslant p$에 대해 $Y_{t - k}$를 곱하고 기댓값을 취하면 다음과 같습니다.
$$
\begin{split}
\mathrm{E} \left( Y_{t} Y_{t - k} \right) & =  \mathrm{E} \left( \phi_{1} Y_{t-1} Y_{t-k} + \phi_{2} Y_{t-2} Y_{t-k} + \dots + \phi_{p} Y_{t -p} Y_{t - k} + \epsilon_{t} Y_{t -k} \right) \\
& =  \phi_{1}  \mathrm{E} \left( Y_{t  - 1} Y_{t - k} \right) + \phi_{2} \mathrm{E} \left( Y_{t - 2} Y_{t - k} \right) + \dots+ \phi_{p} \mathrm{E} \left(Y_{t - p} Y_{t - k} \right) + \mathrm{E} \left( \epsilon_{t} Y_{t  - k} \right).
\end{split}
$$

따라서 자기 공분산은 다음과 같습니다.
$$
\gamma(k) = \phi_{1}\gamma(k -1) + \phi_{2}\gamma(k - 2) + \dots + \phi_{p} \gamma(k  - p),
$$
이는 ACF에 대해 차수 $p$의 *혼합 지수 감쇠*로 바뀝니다.
$$
\rho(k) = \phi_{1} \rho(k - 1) + \phi_{2} \rho(k - 2) + \dots + \phi_{p} \rho(k - p).
$$

감쇠를 식별하려면 매개변수 $\phi_{1}, \phi_{2}, \dots, \phi_{p}$에서 찾을 수 있는 $p$개의 시작 상관 관계 $\rho(1), \rho(2), \dots, \rho(p)$가 필요합니다.

**AR 프로세스의 PACF**

AR($p$) 모형은 $Y_{t+h} = \sum_{i=1}^p\phi_{i} Y_{t + h - i} + \epsilon_{t+h}$를 의미하며, 여기서 $\phi(\lambda)$의 근은 단위 원 외부에 있습니다.
$h > p$일 때 $Y_{t+h}$를 $\{ Y_{t+1},\dots, Y_{t+h-1}\}$에 대한 회귀는 다음과 같습니다.
$$
\hat{Y}_{t+h} = \sum^p_{i=1} \phi_i Y_{t+h-i}.
$$
따라서 $h > p$일 때,
$$
\begin{align}
\rho_{hh} &= \mathrm{cor}(Y_{t+h}-\hat{Y}_{t+h}, Y_t - \hat{Y}_t) \\
& = \mathrm{cor}(\epsilon_{t+h}, Y_t - \hat{Y}_t) \\
& = 0,
\end{align}
$$
프로세스의 인과성으로 인해 차이 $Y_t - \hat{Y}_t$는 $\{ \epsilon_{t+h-1}, \epsilon_{t+h-2},\dots \}$에만 의존하기 때문입니다.

$h\leqslant p$일 때 $\rho_{hh}$는 0이 아니고 $\rho_{11}, \dots, \rho_{p-1,p-1}$은 반드시 0이 아닙니다.

::: {.callout-note}
중요한 결론은 AR($p$) 프로세스의 PACF는 반드시 시차 $p$ 이후에 절단된다는 것입니다(PACF = 0).
:::

::: {.callout-note icon=false}

## 예시: AR(1) 프로세스의 PACF

AR(1) 프로세스의 경우 최적 선형 예측기 $P(X_{n + 1} | X_n) = \phi X_n$입니다.

$h = 0$일 때 $\rho_{00} = 1$입니다.
$h = 1$일 때 $\rho_{11} = \mathrm{cor}(X_t, X_{t+1}) = \phi$입니다(중간 시차 없음, @eq-arACF 참조).
$h = 2$일 때 $X_{t+2} = \phi X_{t+1} + \epsilon_{t+2}$이므로 다음과 같습니다.
$$
\begin{align}
\rho_{22} &= \mathrm{cor}(X_t - P(X_t | X_{t+1}), X_{t+2} - P(X_{t+2} | X_{t+1})) \\
&= \mathrm{cor}(X_t - P(X_t | X_{t+1}), X_{t+2} - \phi X_{t+1})\\
&= \mathrm{cor}(X_t - P(X_t | X_{t+1}), \epsilon_{t+2})\\
&= 0
\end{align}
$$
항 $X_t - P(X_t | X_{t+1})$은 $X_t$와 $X_{t+1}$의 함수일 뿐이고 $\epsilon_{t+2}$는 미래 잡음이기 때문입니다.

따라서 $X_t \sim$ AR(1)의 경우 PACF는 다음과 같습니다.
$$
\rho_{hh} =
\begin{cases}
1 & \text{if } h = 0\\
\phi & \text{if } h = 1\\
0 & \text{if } h \geqslant 2
\end{cases}
$$
:::

@fig-ar1의 다음 AR(1) 프로세스에 대한 그림을 참조하십시오.
$$
X_t = \phi_1 X_{t-1} + \epsilon_t,
$${#eq-ar1}
여기서 $\epsilon_t \sim N(0,\sigma^2)$, $\phi_1=0.6$이고 $\sigma = 1$입니다.

```{r}
#| label: fig-ar1
#| fig-cap: "@eq-ar1에 지정된 AR(1) 프로세스."
#| fig-height: 7

# 이론적 ACF, PACF
phi <- 0.6
RHO <- phi^Lag
ALPHA <- c(1, phi, rep(0, max(Lag) - 1))

# 표본 데이터
X <- arima.sim(list(order = c(1, 0, 0), ar = phi), n = T)

# 그림
p1 <- ggplot(data.frame(Lag, ACF = RHO), aes(x = Lag, y = ACF)) +
    geom_bar(stat = "identity") +
    ggtitle("이론적 ACF")
p2 <- ggplot(data.frame(Lag, PACF = ALPHA), aes(x = Lag, y = PACF)) +
    geom_bar(stat = "identity") +
    ggtitle("이론적 PACF")
p3 <- forecast::autoplot(X) + 
    ggtitle("표본 시계열")
p4 <- forecast::ggAcf(X) + 
    ggtitle("표본 ACF")
p5 <- forecast::ggAcf(X, type = "partial") + 
    ggtitle("표본 PACF")
(plot_spacer() + p1 + p2) / (p3 + p4 + p5) +
    plot_annotation(tag_levels = 'A')
```

@fig-ar2의 다음 AR(1) 프로세스에 대한 그림을 참조하십시오(이전 사양에서 계수 $\phi_1$만 변경됨).
$$
X_t = \phi_1 X_{t-1} + \epsilon_t;\; \epsilon_t \sim N(0,\sigma^2);\; \phi_1=-0.6,\; \sigma = 1.
$${#eq-ar2}

```{r}
#| label: fig-ar2
#| fig-cap: "@eq-ar2에 지정된 AR(1) 프로세스."
#| fig-height: 7

# 이론적 ACF, PACF
phi <- -0.6
RHO <- phi^Lag
ALPHA <- c(1, phi, rep(0, max(Lag) - 1))

# 표본 데이터
X <- arima.sim(list(order = c(1, 0, 0), ar = phi), n = T)

# 그림
p1 <- ggplot(data.frame(Lag, ACF = RHO), aes(x = Lag, y = ACF)) +
    geom_bar(stat = "identity") +
    ggtitle("이론적 ACF")
p2 <- ggplot(data.frame(Lag, PACF = ALPHA), aes(x = Lag, y = PACF)) +
    geom_bar(stat = "identity") +
    ggtitle("이론적 PACF")
p3 <- forecast::autoplot(X) + 
    ggtitle("표본 시계열")
p4 <- forecast::ggAcf(X) + 
    ggtitle("표본 ACF")
p5 <- forecast::ggAcf(X, type = "partial") + 
    ggtitle("표본 PACF")
(plot_spacer() + p1 + p2) / (p3 + p4 + p5) +
    plot_annotation(tag_levels = 'A')
```

AR(1) 모형의 ACF는 계수 $\phi_{1}$이 양수인지 음수인지에 따라 두 가지 그래픽 형태를 취합니다.
첫 번째 경우 감쇠는 양의 축을 통해서만 발생합니다(@fig-ar1).
두 번째 경우 감쇠는 음의 축과 양의 축 사이를 번갈아 가며 발생합니다(@fig-ar2).
이를 *혼합 지수 감쇠*라고 합니다.
두 형태 모두 지수 감쇠의 예이지만 시각적으로 다르게 나타납니다.

AR($p$) 모형의 차수 $p$가 증가함에 따라 ACF의 다양한 시각적 표현 수도 증가합니다.
AR($p$) 모형의 ACF는 매개변수 $\phi_{1}, \phi_{2}, \dots, \phi_{p}$의 부호(양수 또는 음수)에 따라 $2^{p}$개의 다른 그래픽 형태를 취할 수 있습니다.
따라서 AR(2) 모형의 ACF는 $2^{2} = 4$개의 다른 그래픽 형태를 취할 수 있습니다.


## 율-볼드 표현 및 선형 프로세스

프로세스 $X_{t}$($t = 0, \pm 1, \pm 2, \dots$)는 다음과 같은 형태의 표현을 갖는 경우 선형이라고 합니다.
$$
X_{t} = \mu + \sum^{\infty}_{r = - \infty} c_{r} \epsilon_{t - r},
$$
여기서 $\mu$는 공통 평균, $c_{r}$은 고정 상수 시퀀스, $\epsilon_{t}$는 평균이 0이고 공통 분산을 갖는 비상관 확률 변수입니다.

개별 $X_{t}$의 분산이 유한하도록(정상성 및 존재 조건) $\sum c^{2}_{r} < \infty$를 가정합니다.
그러면 프로세스 $X_{t}$는 반드시 (약하게) 정상입니다.

$\epsilon_{t}$가 동일하게 분포한다고 추가로 요구하면 $X_{t}$는 엄격하게 정상입니다.
예를 들어, 정규 분포 $\epsilon_{t}$의 경우를 참조하십시오.

모든 $r < 0$에 대해 $c_r = 0$이면 $X_t$를 *인과적*이라고 합니다(즉, 시간 $t$에서의 프로세스는 미래의 아직 관찰되지 않은 $\epsilon_{t}$ 값에 의존하지 않음).

다음과 같은 형태로 평균이 0인 인과적 정상 프로세스(과거에만 의존) $X_{t}$의 표현
$$
X_{t} = \sum^{\infty}_{r = 0} c_{r} \epsilon_{t - r},
$${#eq-YuleWald}
여기서 $\epsilon_{t} \sim \mathrm{WN}(0, \sigma^{2}$)이고 $\sum c^{2}_{r} < \infty$이며, 때때로 *율-볼드 표현*이라고 합니다.


## 이동 평균 (MA) 모형

**MA(1) 모형**

평균이 0인 정상 프로세스 $Y_{t}$는 $Y_{t}$가 다음을 만족하는 경우 1차 이동 평균 프로세스 또는 *MA(1) 모형*이라고 합니다.
$$
Y_{t} = \epsilon_{t} + \theta_{1}  \epsilon_{t - 1},
$$
여기서 $\epsilon_{t}$는 백색 잡음입니다.

즉, MA(1) 프로세스는 율-볼드 표현 @eq-YuleWald에서 모든 $r > 1$에 대해 $c_{r} = 0$입니다.

MA(1) 모형은 다음과 같이 다시 쓸 수 있습니다.
$$
Y_{t} = (1 + \theta_{1} B) \epsilon_{t},
$$
또는 간결한 형태로
$$
Y_t = \theta (B) \epsilon_t,
$$
여기서 $\theta (\lambda)$는 다항식 $\theta(\lambda) = 1 + \theta_{1} \lambda$입니다.

**MA(q) 모형**

MA(1) 모형을 더 확장하여 다음을 고려할 수 있습니다.
$$
\begin{split}
Y_{t} &= \epsilon_{t} + \theta_{1} \epsilon_{t -1} + \theta_{2} \epsilon_{t - 2} + \dots + \theta_{q} \epsilon_{t - q} \\
&= \epsilon_{t} + \sum_{i=1}^q \theta_i \epsilon_{t-i}.
\end{split}
$$
이 모형을 *차수 $q$의 이동 평균 모형* 또는 MA($q$)라고 합니다.

MA($q$)를 다음과 같이 쓸 수 있습니다.
$$
Y_{t} = \left(1 + \theta_{1} B + \theta_{2} B^{2} + \dots + \theta_{q} B^{q} \right) \epsilon_{t} ,
$$
또는 간결한 형태로
$$
Y_t = \theta (B) \epsilon_t,
$$
여기서 $\theta(\lambda)$는 다항식 $\theta(\lambda) = 1 + \theta_{1} \lambda + \theta_{2} \lambda^{2} + \dots + \theta_{q} \lambda^{q}$입니다.

이제 MA($q$) 프로세스 $Y_{t}$의 ACVF와 ACF를 계산합니다.
$Y_{t}$의 율-볼드 표현을 사용하면 다음과 같습니다.
$$
Y_{t} = \sum^{q}_{r = 0} \theta_{r} \epsilon_{t - r},
$$
자기 공분산은 다음과 같습니다.
$$
\begin{split}
\gamma_Y(h) & = \mathrm{cov}(Y_{t}, Y_{t+h}) = \mathrm{cov} \left( \sum^{q}_{r = 0} \theta_{r }\epsilon_{t - r}, \sum^{q}_{\ell = 0} \theta_{\ell} \epsilon_{t + h - \ell} \right) \\
\\
& = \sum^{q}_{r = 0} \sum^{q}_{\ell = 0} \mathrm{cov} \left( \theta_{r } \epsilon_{t - r},  \theta_{\ell} \epsilon_{t + h - \ell} \right) \\
\\
& = \sum^{q}_{r = 0} \sum^{q}_{\ell = 0} \theta_{r } \theta_{\ell} \mathrm{cov}  \left( \epsilon_{t - r}, \epsilon_{t - r}  \right) ~~ \text{since cov} \left( \epsilon_{u}, \epsilon_{v}  \right) = 0 ~ \text{unless} ~ u = v \\
\\
& = \sigma_{\epsilon}^{2} \sum^{q}_{r = 0} \theta_{r} \theta_{r+h}.
\end{split}
$$
잡음 계열 간에 시간 이동이 없는 경우, 즉 $t-r = t+h-l$일 때 $l=r+h$가 되며, 이는 마지막 행에서 사용됩니다.

따라서,
$$
\gamma_Y(h) = \left\{
\begin{array}{lcl}
\sigma_{\epsilon}^{2} \sum^{q  - h}_{r = 0} \theta_{r} \theta_{r+h} & \text{for} &  h \leqslant q;\\
0 & \text{for} & h > q.
\end{array}
\right.
$${#eq-MAacvf}

이는 MA($q$) 프로세스의 상관 구조에 대한 가장 중요한 결과로 이어집니다.
MA($q$) 프로세스의 경우 모든 $h > q$에 대해 $\gamma(h) = 0$입니다.
동등하게 ACF는 $q$개의 '시작' 상관 관계 또는 스파이크 $\rho(1), \rho(2), \dots, \rho(q)$를 가지며, 그 후 $h > q$에 대해 $\rho(h) = 0$입니다.
ACF는 시차 $q$ 이후에 '절단'된다고 말합니다.

이제 매개변수 $\theta_{0} = 1, \theta_{1}, \theta_{2}, \dots, \theta_{q}$의 관점에서 시작 상관 관계 $\rho(1), \dots, \rho(q)$의 실제 값을 계산합니다.
@eq-MAacvf를 사용하면 다음과 같습니다.

* MA(1) 모형의 경우 $q = 1$입니다. 따라서
$$
\begin{split}
h  =  0 &\rightarrow \gamma(0) = \sigma^{2} \sum^{1}_{ r=0}  \theta^{2}_{r} = \sigma^{2} \left( \theta^{2}_{0} + \theta^{2}_{1} \right) = \sigma^{2} \left(1 + \theta^{2}_{1}\right). \\
\\
h  =  1 &\rightarrow \gamma(1) = \sigma^{2}  \sum^{0}_{ r=0}  \theta_{r} \theta_{r + 1} = \sigma^{2} \theta_{0} \theta_{1} = \sigma^{2} \theta_{1}.
\end{split}
$$

    따라서 $\rho(1) = \gamma(1) / \gamma(0) = \theta_{1} / (1 + \theta^{2}_{1})$입니다.

* MA(2) 모형의 경우 $q = 2$입니다. 따라서
$$
\begin{split}
h =  0 &\rightarrow \gamma(0) = \sigma^{2} \sum^{2}_{r=0}  \theta^{2}_{r} = \sigma^{2} \left(1 + \theta^{2}_{1} + \theta^{2}_{2}\right). \\
\\
h  =  1 &\rightarrow \gamma(1) = \sigma^{2} \sum^{1}_{r=0}  \theta_{r} \theta_{r + 1} = \sigma^{2} \left(\theta_{1} + \theta_{1} \theta_{2} \right) = \sigma^{2} \theta_{1}  \left(1 + \theta_{2}\right). \\
\\
h  =  2 &\rightarrow \gamma(2) = \sigma^{2} \sum^{0}_{r=0}  \theta_{r} \theta_{r + 2} = \sigma^{2} \theta_{2}.
\end{split}
$$
    따라서 $\rho(1) = \frac{\gamma(1)}{\gamma(0)} = \frac{\theta_{1} \left(1 + \theta_{2} \right)}{1+ \theta^{2}_{1} + \theta^{2}_{2}}$이고 $\rho(2) = \frac{\gamma(2)}{\gamma(0)} = \frac{\theta_{2}}{1+ \theta^{2}_{1} + \theta^{2}_{2}}$입니다.

* MA($q$) 모형에 대해서도 유사하게 진행합니다.

MA($q$)의 상관 계수를 얻는 또 다른 방법은 공분산의 쌍선형 속성을 사용하고 백색 잡음 항 간의 상호 작용을 결정하여 공분산 $\gamma(h) = \mathrm{cov} (Y_{t}, Y_{t - h} )$를 직접 유도하는 것입니다.
이 방법의 장점은 아무것도 외울 필요가 없다는 것입니다.
또한 백색 잡음은 $u \neq v$일 때마다 $\mathrm{cov} (\epsilon_{u}, \epsilon_{v}) = 0$이라는 속성을 가지므로 시간 색인이 일치할 때만, 즉 $u = v$일 때만 상호 작용이 발생합니다.

::: {.callout-note icon=false}
        
## 예시: MA(1)의 ACVF 및 ACF

MA(1) 모형을 고려하십시오.
$h \geqslant 0$이라고 합시다.
공분산 속성을 적용하면 일반적인 표현식을 얻습니다.
$$
\begin{split}
\gamma(h) & = \mathrm{cov}\left( Y_{t}, Y_{t - h} \right) \\
& = \mathrm{cov} \left( \epsilon_{t} + \theta_{1} \epsilon_{t - 1},\; \epsilon_{t - h} + \theta_{1} \epsilon_{t - h - 1}  \right) \\
& =  \mathrm{cov} \left( \epsilon_{t},  \epsilon_{t - h} \right) + \theta_{1} \mathrm{cov} \left(  \epsilon_{t},  \epsilon_{t - h - 1}  \right) + \theta_{1} \mathrm{cov} \left( \epsilon_{t - 1}, \epsilon_{t - h} \right) + \theta^{2}_{1} \mathrm{cov} \left(\epsilon_{t - 1}, \epsilon_{t - h - 1} \right).
\end{split}
$$

위 표현식의 마지막 줄에 있는 공분산은 시간 색인이 일치하면 0이 아닙니다.
위 방정식에 다른 $h$ 값을 대입하면 다음과 같습니다.
$$
\begin{align}
h  =  0 \rightarrow \gamma(0) &= \mathrm{cov} \left( \epsilon_{t}, \epsilon_{t} \right) + 0 + 0 + \theta^{2}_{1} \mathrm{cov} \left( \epsilon_{t - 1}, \epsilon_{t - 1} \right) \\
&= \sigma^{2} + \theta^{2}_{1} \sigma^{2} \\
&= \sigma^{2} \left( 1 + \theta^{2}_{1} \right). \\
\\
h = 1 \rightarrow \gamma(1) &= 0 + 0 + \theta_{1} \mathrm{cov} \left( \epsilon_{t - 1}, \epsilon_{t - 1} \right) + 0 \\
&= \sigma^{2} \theta_{1}.\\
\\
h \geqslant 2 \rightarrow \gamma(h) &= 0 + 0 + 0 + 0 \\
&= 0.
\end{align}
$$

이 방법은 고차 MA($q$) 모형의 자기 공분산을 계산하는 데 쉽게 일반화됩니다.

ACF는 분산(시차 0에서의 ACVF)으로 표준화된 ACVF이므로 ACF는 다음과 같습니다.
$$
\begin{align}
\rho(h) &= \frac{\gamma(h)}{\gamma(0)} \\
&= 
\begin{cases}
1 & \text{if } h = 0 \\
\frac{\theta_1}{1 + \theta^2_1} & \text{if } h = 1 \\
0 & \text{if } h > 1
\end{cases}
\end{align}
$$
:::

::: {.callout-note}
MA($q$) 프로세스의 ACF 구조를 명시적으로 결정했습니다.
가장 중요한 특징은 $h > q$에 대해 $\rho(h) = 0$이라는 것입니다.
MA 프로세스에 대해 이것을 기억하십시오.
:::

$\theta_{r}$ 계수의 관점에서 $\rho(h)$를 표현하는 것과 같은 더 미세한 특징은 위와 같이 결정할 수 있습니다.

**MA 프로세스의 PACF**

MA($q$)의 경우 $Y_t = -\sum_{j=1}^{\infty} \pi_j Y_{t-j} + \epsilon_t$로 쓸 수 있습니다.
또한 유한 표현은 존재하지 않습니다.
이 결과로부터 PACF는 AR($p$)의 경우와 같이 절대로 절단되지 않는다는 것이 명백해야 합니다.
MA(1)의 경우 $Y_t = \epsilon_t +\theta \epsilon_{t-1}$이고 $|\theta| < 1$이면 다음과 같이 나타낼 수 있습니다[@Shumway:Stoffer:2014].
$$
\rho_{hh} = - \frac{(-\theta)^h (1 - \theta^2)}{1 - \theta^{2(h+1)}}, \; h \geqslant 1.
$$

::: {.callout-note}
모든 MA($q$) 프로세스는 무한 자기회귀 확장을 가지며 PACF는 절대로 절단되지 않습니다.
실제로 MA($q$) 프로세스의 PACF는 차수 $q$의 혼합 지수 감쇠에 따라 감쇠하는 것으로 나타낼 수 있습니다.
:::

먼저 수많은 회귀를 수행하여 PACF를 계산할 필요는 없습니다.
계산은 재귀 공식을 통해 수행됩니다.

위의 AR(1) 예제와 유사하게 이제 양수 및 음수 계수를 갖는 MA(1) 프로세스에 대한 두 가지 그림 세트를 고려하십시오.
MA(1) 프로세스
$$
X_t = \theta_1 \epsilon_{t-1} + \epsilon_t,
$${#eq-ma1}
여기서 $\epsilon_t \sim N(0,\sigma^2)$, $\theta_1=0.3$이고 $\sigma = 1$이며, 그림은 @fig-ma1을 참조하십시오.

```{r}
#| label: fig-ma1
#| fig-cap: "@eq-ma1에 지정된 MA(1)."
#| fig-height: 7

# 이론적 ACF, PACF
theta <- 0.3
RHO <- c(1, theta/(1 + theta^2), rep(0, max(Lag) - 1))
ALPHA <- c(1, ARMAacf(ma = theta, lag.max = max(Lag), pacf = TRUE))

# 표본 데이터
X <- arima.sim(list(order = c(0, 0, 1), ma = theta), n = T)

# 그림
p1 <- ggplot(data.frame(Lag, ACF = RHO), aes(x = Lag, y = ACF)) +
    geom_bar(stat = "identity") +
    ggtitle("이론적 ACF")
p2 <- ggplot(data.frame(Lag, PACF = ALPHA), aes(x = Lag, y = PACF)) +
    geom_bar(stat = "identity") +
    ggtitle("이론적 PACF")
p3 <- forecast::autoplot(X) + 
    ggtitle("표본 시계열")
p4 <- forecast::ggAcf(X) + 
    ggtitle("표본 ACF")
p5 <- forecast::ggAcf(X, type = "partial") + 
    ggtitle("표본 PACF")
(plot_spacer() + p1 + p2) / (p3 + p4 + p5) +
    plot_annotation(tag_levels = 'A')
```

음수 $\theta_1$을 갖는 MA(1) 프로세스의 경우,
$$
X_t = \theta_1 \epsilon_{t-1} + \epsilon_t,
$${#eq-ma2}
여기서 $\epsilon_t \sim N(0,\sigma^2)$, $\theta_1=-0.3$이고 $\sigma = 1$이며, 그림은 @fig-ma2를 참조하십시오.

```{r}
#| label: fig-ma2
#| fig-cap: "@eq-ma2에 지정된 MA(1)."
#| fig-height: 7

# 이론적 ACF, PACF
theta <- -0.3
RHO <- c(1, theta/(1 + theta^2), rep(0, max(Lag) - 1))
ALPHA <- c(1, ARMAacf(ma = theta, lag.max = max(Lag), pacf = TRUE))

# 표본 데이터
X <- arima.sim(list(order = c(0, 0, 1), ma = theta), n = T)

# 그림
p1 <- ggplot(data.frame(Lag, ACF = RHO), aes(x = Lag, y = ACF)) +
    geom_bar(stat = "identity") +
    ggtitle("이론적 ACF")
p2 <- ggplot(data.frame(Lag, PACF = ALPHA), aes(x = Lag, y = PACF)) +
    geom_bar(stat = "identity") +
    ggtitle("이론적 PACF")
p3 <- forecast::autoplot(X) + 
    ggtitle("표본 시계열")
p4 <- forecast::ggAcf(X) + 
    ggtitle("표본 ACF")
p5 <- forecast::ggAcf(X, type = "partial") + 
    ggtitle("표본 PACF")
(plot_spacer() + p1 + p2) / (p3 + p4 + p5) +
    plot_annotation(tag_levels = 'A')
```


## ARMA

ARMA($p, q$)는 $p$개의 자기회귀 구성 요소와 $q$개의 이동 평균 구성 요소의 혼합입니다.
다음과 같이 표현할 수 있습니다.
$$
\phi^{p} (B)Y_{t} = \theta^{q} (B) \epsilon_{t},
$${#eq-armapq}
여기서 $\epsilon_t$는 평균이 0이고 분산이 $\sigma^2$인 백색 잡음이고, $\phi^{p}(\lambda)$와 $\theta^{q}(\lambda)$는 각각 차수가 $p$와 $q$인 다항식(공통 근 없음)입니다.

ARMA($p, q$) @eq-armapq는 다음과 같이 확장할 수 있습니다.
$$
X_t - \phi_1 X_{t-1} - \dots - \phi_p X_{t-p} = \epsilon_t + \theta_1 \epsilon_{t-1} + \dots + \theta_q \epsilon_{t-q}.
$$

**ARMA(1,2)**

간단한 표기법 $\phi^{1} (B)Y_{t} = \theta^{2} (B) \epsilon_{t}$는 다음과 같이 확장됩니다.
$$
\left(1 - \phi_{1} B \right) Y_{t} = \left( 1 + \theta_{1} B + \theta_{2} B^{2} \right) \epsilon_{t}
$$
그리고 다음과 같습니다.
$$
Y_{t} - \phi_{1} Y_{t - 1} = \epsilon_{t} + \theta_{1} \epsilon_{t - 1} + \theta_{2}\epsilon_{t - 2}.
$$

방정식의 왼쪽에 $Y_{t}$를 분리하여 확장의 최종 형태를 얻습니다.
$$
Y_{t} = \phi_{1} Y_{t -1} + \epsilon_{t} + \theta_{ 1} \epsilon_{t - 1} + \theta_{2} \epsilon_{t-2}.
$$

**ARMA(3,1)**

간단한 표기법 $\phi^{3} (B)Y_{t} = \theta^{1} (B) \epsilon_{t}$는 다음과 같이 확장됩니다.
$$
\left( 1 -  \phi_{1} B - \phi_{2} B^{2}  - \phi_{3} B^{3} \right) Y_{t} = \left( 1 + \theta_{1} B \right) \epsilon_{t}
$$
또는
$$
Y_{t} - \phi_{1} Y_{t - 1} - \phi_{2} Y_{t - 2} - \phi_{3} Y_{t - 3} = \epsilon_{t} + \theta_{1} \epsilon_{t-1}.
$$

$Y_{t}$를 분리하면 최종 형태는 다음과 같습니다.
$$
Y_{t} = \phi_{1} Y_{t - 1} + \phi_{2} Y_{t - 2} + \phi_{3} Y_{t - 3} + \epsilon_{t} + \theta_{1} \epsilon_{t-1}.
$$

혼합 ARMA($p, q$) 프로세스($p > 0$, $q > 0$)에서는 ACF도 PACF도 갑자기 절단되지 않습니다.
ACF와 PACF 모두 혼합 지수 감쇠를 나타냅니다.
이는 AR 구성 요소가 ACF에 혼합 지수 감쇠를 도입하고 MA 구성 요소가 PACF에 혼합 지수 감쇠를 도입하기 때문에 발생합니다.


## AR/MA/ARMA 모형 요약

적절한 모형 사양을 결정하려면 다음 요약 또는 @tbl-arma를 사용하십시오.

AR($p$) 모형: $\phi^{p} (B)Y_{t}  = \epsilon_{t}$

* ACF: $p$개의 초기 스파이크, 그 후 차수 $p$의 혼합 지수 감쇠로 감쇠함 (절대로 0이 아님)
* PACF: $p$개의 초기 스파이크, 그 후 절단됨; $h > p$에 대해 PACF($h$) = 0

MA($q$) 모형: $Y_{t} = \theta^{q} (B) \epsilon_{t}$

* ACF: $q$개의 초기 스파이크, 그 후 절단됨; $h > q$에 대해 ACF($h$) = 0
* PACF: $q$개의 초기 스파이크, 그 후 차수 $q$의 혼합 지수 감쇠로 감쇠함 (절대로 0이 아님)

ARMA($p,q$) 모형 ($p>0$, $q>0$): $\phi^{p} (B)Y_{t} = \theta^{q} (B) \epsilon_{t}$

* ACF: 최대 ($p, q$)개의 초기 스파이크, 그 후 AR($p$) 구성 요소에 의해 구동되는 혼합 지수 감쇠로 감쇠함 (절대로 0이 아님)
* PACF: 최대 ($p, q$)개의 초기 스파이크, 그 후 MA($q$) 구성 요소에 의해 구동되는 혼합 지수 감쇠로 감쇠함 (절대로 0이 아님)

모형 | ACF | PACF |
|------|------|------|
MA($q$) | 시차 $q$ 이후 0 | 지수 감쇠 |
AR($p$) | 지수 감쇠 | 시차 $p$ 이후 0 |
ARMA($p$,$q$) | 혼합 지수 감쇠 | 혼합 지수 감쇠 |

: ARMA($p, q$) 모형 요약 {#tbl-arma}

실제로 ARMA의 차수 $p$와 $q$의 최종 선택(즉, 모형 사양)은 종종 다음에 기반합니다.

* AIC 또는 BIC와 같은 정보 기준 또는
* 예측 정확도 (예: 테스트 세트에 대한 점 예측의 PRMSE 및 PMAE)

@tbl-arma의 규칙 구현을 연습하려면 @sec-acfpractice의 예제를 사용하십시오.


## 분석 예시

```{r}
#| echo: false

set.seed(1)
Y <- arima.sim(list(order = c(2, 0, 1), ar = c(0.5, 0.3), ma = c(0.2)), n = T)
```

단변량 시계열 $Y_t$가 주어졌다고 가정합니다.

먼저 데이터를 그립니다(@fig-simYt).

```{r}
#| label: fig-simYt
#| fig-cap: "시계열 $Y_t$의 그림."

ggplot2::autoplot(Y)
```

명백한 추세가 없으면 표본 ACF와 PACF를 그립니다(@fig-simYtacf).

```{r}
#| label: fig-simYtacf
#| fig-cap: "$Y_t$의 추정된 ACF 및 PACF."

p1 <- forecast::ggAcf(Y) +
    ggtitle("")
p2 <- forecast::ggAcf(Y, type = "partial") +
    ggtitle("")
p1 + p2 +
    plot_annotation(tag_levels = 'A')
```

그림(@fig-simYtacf)을 기준으로 *ACF는 선형보다 빠르게 감쇠*하고(정상성의 일부 표시), *PACF는 시차 2까지 0이 아닙니다*(시차 2 이후 절단됨).
ARMA 모형에 대한 ACF 및 PACF의 예상 동작을 알고 있으므로(@tbl-arma 참조) 이 경우 AR(2)를 제안할 수 있으며, 이는 ARMA(2,0)과 동일합니다.

ACF 및 PACF 추정치에 영향을 미치는 잠재적인 표본 변동성을 감안할 때 선택한 것과 유사하거나 시각적 분석을 기반으로 선택한 것과 비교할 때 약간 더 나은 성능을 보일 수 있는 다른 모형 사양이 있을 수 있습니다.
예를 들어, 식별한 최대 시차 2 내에서 다른 적절한 조합을 확인할 수 있습니다: ARMA(1,0), (2,0), (0,1), (1,1), (2,1), (0,2), (1,2) 및 ARMA(2,2).
선택 사항이 너무 많으므로 최상의 모형을 선택하기 위한 정량적 기준이 필요합니다.

아래 코드는 지정된 세트에서 모형을 선택하기 위해 아카이케 및 베이즈 정보 기준(AIC 및 BIC)을 계산하는 '수동' 접근 방식을 사용하지만, 더 자동으로 수행하는 R 함수는 다음 섹션을 참조하십시오.

```{r}
#| code-fold: false

# p = q = 0을 제외한 p와 q의 조합
results <- expand.grid(p = c(0, 1, 2), q = c(0, 1, 2))[-1, ] 
for (i in 1:nrow(results)) {
    mod <- arima(Y, order = c(results$p[i], 0, results$q[i]))
    results$aic[i] <- mod$aic
    results$bic[i] <- BIC(mod)
}
results
```


### 자동 모형 선택

예를 들어, 함수 `stats::ar()`은 기본적으로 율-워커 방법을 사용하여 계수를 추정하고 AIC를 사용하여 AR($p$) 모형에 대한 최상의 차수를 선택하며, 여기서 $p$의 최대값은 사용자가 설정할 수 있습니다.

```{r}
#| code-fold: false

ar(Y, order.max = 11)
```

함수 `funtimes::ARest()`는 `stats::ar()`의 래퍼입니다.
@Hall:VanKeilegom:2003의 차분 기반 추정량을 추가하며, 이는 이제 기본적으로 사용되며 모델 선택 기준으로 BIC 또는 AIC 간에 전환합니다.
선택은 MA 항의 가능성을 고려하지 않고 AR($p$)의 차수 $p$에 대해서만 수행됩니다.

```{r}
#| code-fold: false

funtimes::ARest(Y)
```

`stats::ar()`과의 일치 여부를 확인하려면 방법을 변경하고 `ar.order`를 수정합니다(자동 선택 끄기).
```{r}
#| code-fold: false

funtimes::ARest(Y, ar.method = "yw", ar.order = 2, ic = "none")
```

::: {.callout-note}
BIC는 AIC보다 더 간결한 모형을 선택합니다.
이러한 더 간단한 모형은 일반적으로 예측 작업에 선호됩니다.
:::

함수 `fable::ARIMA()`는 일부 차수 제약 조건 내에서 가능한 ARMA 모형을 검색합니다(기본 최대 차수 및 검색 전략은 위의 두 함수와 다름 - R의 각 함수에 대한 도움말 파일 참조).
이 함수는 함수 `forecast::auto.arima()`의 후속 함수이며 ARMA 모형을 추정하고 선택하는 데 가장 포괄적인 R 함수일 것입니다.
ARMA($p,q$) 모형뿐만 아니라 과정 후반부에 설명될 더 복잡한 모형도 적합시키고 선택할 수 있습니다.

```{r}
#| code-fold: false

library(fable)
m <- as_tsibble(Y) %>% 
    model(ARIMA(Y ~ 1, ic = "bic"))
report(m)
```

고려된 모든 경우에서 AR(2)와 동일한 모형 ARMA(2,0)가 선택되었습니다.
다음 단계는 잔차 진단입니다. 잔차의 등분산성, 비상관성 및 정규성을 확인합니다(@fig-resfable).

```{r}
#| label: fig-resfable
#| fig-cap: "`fable` 패키지를 사용하여 추정된 ARMA(2,0) 모형에 대한 잔차 진단."
#| fig-height: 7

feasts::gg_tsresiduals(m)
```

그림을 기준으로 잔차는 가정을 위반하지 않으므로 예측을 진행합니다(@fig-fcstfable).

```{r}
#| label: fig-fcstfable
#| fig-cap: "`fable` 패키지를 사용하여 추정된 ARMA(2,0) 모형에서 10단계 앞 예측."

m %>%
    fabletools::forecast(h = 10) %>%
    autoplot(Y)
```

그러나 `fable` 패키지의 구문과 출력은 일반적인 R 대안과 상당히 다릅니다.
`ggplot2` 패키지를 사용하여 여전히 그림을 그리지만 기본 R 함수를 사용하여 얻은 결과는 @fig-res를 참조하십시오.
또한 잔차 진단을 위해 기본 R 함수 `tsdiag()`를 참조하십시오.

```{r}
#| label: fig-res
#| fig-cap: "기본 R 함수 `stats::arima()`를 사용하여 추정된 ARMA(2,0) 모형의 잔차 진단 및 10단계 앞 예측."
#| fig-height: 9

m <- arima(Y, order = c(2, 0, 0))
e <- m$residuals
p1 <- ggplot2::autoplot(e) + 
    ylab("잔차")
p2 <- forecast::ggAcf(e) +
    ggtitle("")
p3 <- ggpubr::ggqqplot(e) + 
    xlab("표준 정규 분위수")
p4 <- ggplot2::autoplot(forecast::forecast(m, h = 10))
p1 / (p2 + p3) / p4 +
    plot_annotation(tag_levels = 'A')
```

추정된 잔차 $\hat{\epsilon}_t = Y_t - \hat{Y}_t$를 사용하여 '적합된' 값 $\hat{Y}_t$(기술적으로 이는 1단계 앞 예측임)를 얻을 수 있습니다(@fig-simYtfit 참조).

```{r}
#| label: fig-simYtfit
#| fig-cap: "관찰된 시계열(검은색)과 ARMA(2,0) 모형의 1단계 앞 예측(빨간색)."

Fit <- Y - e
ggplot2::autoplot(Y) + 
    autolayer(Fit) +
    ylab("Y")
```


## 결론

AR, MA 및 ARMA 모형을 정의하고 이러한 모형에 해당하는 시계열 프로세스가 약한 정상성 조건을 만족함을 보였습니다.

ACF 및 PACF 그림을 사용하여 ARMA 모형을 지정하기 위해 차수 $p$와 $q$를 선택할 수 있지만, 경쟁 모형에 대해 다양한 평가 및 검정을 실행하는 다양한 함수도 사용할 수 있습니다.

추정 방법(즉, 추정량)과 모형 비교 방법을 선택해야 합니다.

ARMA 모형에 가장 자주 사용되는 추정량은 다음과 같습니다.

* 최대 우도,
* 율-워커, 및
* 버그.

OLS 기반 추정량은 덜 자주 사용됩니다.

경쟁 모형을 비교하는 방법에는 다음이 포함될 수 있습니다.

* 표본 내(훈련) 적합도를 평가하기 위한 로그 우도, MAE, RMSE 및 정보 기준;
* 잔차의 진단 검사(잔차가 검정을 통과하지 못하면 모형 폐기);
* 테스트 세트에서 모형 비교(PMAE, PRMSE, 예측 구간의 포함 범위 및 너비).

이러한 각 옵션에 대해 여러 R 함수를 사용할 수 있거나 처음부터 작성할 수 있습니다.
